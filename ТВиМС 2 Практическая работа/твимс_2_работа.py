# -*- coding: utf-8 -*-
"""ТВиМС 2 работа.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dxgx4Wpb_BaNmQl_ONzCccqBID3BWxXc
"""

import pandas as pd
import itertools
import scipy.stats
import math

"""Документация на pandas.DataFrame https://pandas.pydata.org/pandas-docs/stable/reference/frame.html

Документация на scipy
https://docs.scipy.org/doc/scipy/index.htm

Статистические функции
https://docs.scipy.org/doc/scipy/tutorial/stats.html

Биномиальное распределение https://docs.scipy.org/doc/scipy/tutorial/stats/discrete_binom.html

Распределение Пуассона https://docs.scipy.org/doc/scipy/tutorial/stats/discrete_poisson.html

Нормальное распределение https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm
https://pieriantraining.com/working-with-scipy-stats-norm-a-guide/

"""

Nmin = 10
Nmax = 1000
step = 10

# список с количествами экспериментов
ExperimentsNumber = [i for i in range(Nmin, Nmax+1, step)]

# вероятности успеха
prob = [0.0005, 0.005, 0.05, 0.25, 0.5, 0.75, 0.9, 0.95, 0.995, 0.9995]

print(ExperimentsNumber)

# для каждого количества должно быть 10 вероятностей
# experiments number, probability
# создаёт пары вида: количество экспериментов, вероятность успеха
ExNumberProb = itertools.product(ExperimentsNumber, prob)

df = pd.DataFrame()
ColumnNames = [ "Количество опытов, n", "Количество успехов, m", "Вероятность успеха, p", "Вероятность P(X=m) по формуле Бернулли",
                "Вероятность P(X=m) по формуле Пуассона", "Вероятность P(X=m) по формуле нормального распределения",
                "Модуль отклонения биномиального от Пуассона", "Модуль отклонения биномиального от нормального", "Модуль отклонения Пуассона от нормального", "Среднняя погрешность"]

# это не запускать, а то придётся заново создавать эту переменную
# она, судя по всему, работает как генератор т.е. выполняется только 1 раз.
for n, p in ExNumberProb:
    print(n,p)

"""Код, который всё считает и создаёт датафрейм. Выполняется за 55 минут (почему-то потом за 29, видимо, колаб тогда где-то завис). Очень долго, надо будет потом показать код Игорю Андреевичу и спросить, что с ним не так, а то он говорил, что у него код выполнился за пару минут."""

# пары вида: количество экспериментов, вероятность успеха
# например 10 0.0005
for n, p in ExNumberProb:

    q = 1-p

    # математическое ожидание
    mean = n*p
    # дисперсия
    variance = n*p*q

    # биномиальное распределение
    # binomial distribution
    bd = scipy.stats.binom(n,p)

    # распределение Пуассона
    # Poisson distribution
    # не pd, так как это отвечает за pandas
    poisd = scipy.stats.poisson(mean)

    # нормальное распределение с мат. ожиданием np и ско npq. Второй параметр тут - ско, а не дисперсия
    # normal distribution
    nd = scipy.stats.norm(mean,math.sqrt(variance))

    # i - количество успехов.
    # для 10 опытов это будет от 0 до 10 включительно
    for i in range(n+1):

        # вероятности
        # pmf - probability mass function - функция вероятности, для дискретных СВ
        # pdf - probability dencity function - плотность вероятности, для непрерывных СВ
        bdprob = bd.pmf(i)
        poisdprob = poisd.pmf(i)
        ndprob = nd.pdf(i)

        # создание словаря с полученными данными
        data=[[n], [i], [p], [bdprob], [poisdprob], [ndprob],  [abs(bdprob-poisdprob)], [abs(bdprob-ndprob)], [abs(poisdprob-ndprob)],[(bdprob+poisdprob+ndprob)/3]]
        temp = dict(zip(ColumnNames, data))

        # добавляет данные в датафрейм
        newdf = pd.DataFrame(temp)
        df = pd.concat([df,newdf], ignore_index=True,  axis = 0)

df

# сохраню этот файл себе, чтобы потом не считать всё снова.
df.to_csv("ТВиМС 2 работа, датафрейм.csv", sep=',', encoding='utf-8')
df.to_excel("ТВиМС 2 работа, датафрейм.xlsx")

# Стандартное отклонение для каждого столбца
df.std()

"""# Контрольные вопросы

## 1 Для каких пар значений n, p применимо приближённое вычисление вероятности при помощи распределения Пуассона?

Распределение Пуассона, вместо биномиального, можно применять, если вероятность успеха p стремится к нулю, а число экспериментов n - к бесконечности.

Рассмотрим график отклонения вероятности, посчитанной по формуле Бернулли, от вероятнсоти по формуле Пуассона.
Из графика видно, что, при одном и том же количестве опытов, отклонение биномиального от Пуассона тем меньше, чем меньше вероятность успеха.

В некоторых местах график показывает нулевое значение, это, видимо, связано с тем, что числа настолько маленькие, что компьютер округляет их до нуля. Там, где он смог посчитать значения, они меньше при наименьшей вероятности.
"""

# График почему-то имеет странную форму. Спрошу потом у Игоря Андреевича.

df1 = df[df['Количество опытов, n'] == 1000]
df1 = df1[df1['Вероятность успеха, p'] == 0.95]

df1['Модуль отклонения биномиального от Пуассона'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от Пуассона при n = 1000, p = 0.95')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df2 = df[df['Количество опытов, n'] == 1000]
df2 = df2[df2['Вероятность успеха, p'] == 0.5]

df2['Модуль отклонения биномиального от Пуассона'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от Пуассона при n = 1000, n = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df3 = df[df['Количество опытов, n'] == 1000]
df3 = df3[df3['Вероятность успеха, p'] == 0.05]

df3['Модуль отклонения биномиального от Пуассона'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от Пуассона при n = 1000, n = 0.05')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

"""Пример того, что компьюет окгуляет слишком маленькиие значения до нуля."""

df1 = df[df['Количество опытов, n'] == 1000]
df1 = df1[df1['Вероятность успеха, p'] == 0.95]
df1.head(20)

"""## 2 Для каких пар значений n, p применимо приближённое вычисление вероятности при помощи локальной теоремы Муавра-Лапласа?

см. Гнеденко, стр 96-97
https://psv4.userapi.com/s/v1/d/6NMy4u3YcDHrFFcPKRzzAcW4_7z4LEgd4Q-FoWYiOUUyp_15sYs0xEiCf_TdMsFYwc_Vlf3zcBsJgaKAI0R3-BaNVb6xgdTK2dNGAdpFcBz8K6tHXAvEYw/Gnedenko_B_V_-_Kurs_teorii_veroyatnostey_Izd.pdf

Число n должно быть достаточно большим, больше нескольких сотен, а p - не слишком близким к нулю или единице. Формула работает тем лучше, чем больше n и чем p ближе к 0,5.

Из графиков видно, что из трёх рассмотренных вариантов, p = [0.05, 0.5, 0.95] погрешность была меньше, когда вероятность составила 0.5
"""

df1 = df[df['Количество опытов, n'] == 1000]
df1 = df1[df1['Вероятность успеха, p'] == 0.05]

df1['Модуль отклонения биномиального от нормального'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от нормального при n = 100, p = 0.05')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df2 = df[df['Количество опытов, n'] == 1000]
df2 = df2[df2['Вероятность успеха, p'] == 0.5]

df2['Модуль отклонения биномиального от нормального'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от нормального при n = 100, n = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df3 = df[df['Количество опытов, n'] == 1000]
df3 = df3[df3['Вероятность успеха, p'] == 0.95]

df3['Модуль отклонения биномиального от нормального'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от нормального при n = 100, n = 0.95')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

"""## 3 Как влияет на результаты увеличение значения n?
Рассмотрим отклонение биномиального от Пуассона и нормального при одной и той же вероятности, но разном количестве опытов: 50, 500, 1000. Из графиков видно, что в обоих случаях минимальное отклонение будет при самом большом n.

"""

df1 = df[df['Количество опытов, n'] == 50]
df1 = df1[df1['Вероятность успеха, p'] == 0.5]

df1['Модуль отклонения биномиального от Пуассона'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от Пуассона при n = 50, p = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df2 = df[df['Количество опытов, n'] == 500]
df2 = df2[df2['Вероятность успеха, p'] == 0.5]

df2['Модуль отклонения биномиального от Пуассона'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от Пуассона при n = 500, n = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df3 = df[df['Количество опытов, n'] == 1000]
df3 = df3[df3['Вероятность успеха, p'] == 0.5]

df3['Модуль отклонения биномиального от Пуассона'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от Пуассона при n = 1000, n = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df1 = df[df['Количество опытов, n'] == 50]
df1 = df1[df1['Вероятность успеха, p'] == 0.5]

df1['Модуль отклонения биномиального от нормального'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от нормального при n = 50, p = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df2 = df[df['Количество опытов, n'] == 500]
df2 = df2[df2['Вероятность успеха, p'] == 0.5]

df2['Модуль отклонения биномиального от нормального'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от нормального при n = 500, n = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

df3 = df[df['Количество опытов, n'] == 1000]
df3 = df3[df3['Вероятность успеха, p'] == 0.5]

df3['Модуль отклонения биномиального от нормального'].plot(kind='line', figsize=(8, 4), title='Модуль отклонения биномиального от нормального при n = 1000, n = 0.5')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

"""# Тест. Потом убрать"""

import math
n = 100
p = 0.8
temp = scipy.stats.binom(n,p)
print(temp.cdf(101))

temp1 = scipy.stats.poisson(n*p)
print(temp1.cdf(1/(n*p)))

# математическое ожидание
mean = n*p
# дисперсия
variance = n*p*(1-p)
# нормальное распределение с мат. ожиданием np и ско npq. Второй параметр тут - ско, а не дисперсия
temp2 = scipy.stats.norm(mean,math.sqrt(variance))
print(temp2.cdf(mean+3*math.sqrt(variance))-temp2.cdf(mean-3*math.sqrt(variance)))

import numpy as np
from scipy.stats import binom
import matplotlib.pyplot as plt
fig, ax = plt.subplots(1, 1)

n, p = 1000, 0.5
mean, var, skew, kurt = binom.stats(n, p, moments='mvsk')

x = np.arange(binom.ppf(0.01, n, p),
              binom.ppf(0.99, n, p))
ax.plot(x, binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')
ax.vlines(x, 0, binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)

rv = binom(n, p)
ax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,
        label='frozen pmf')
ax.legend(loc='best', frameon=False)
plt.show()